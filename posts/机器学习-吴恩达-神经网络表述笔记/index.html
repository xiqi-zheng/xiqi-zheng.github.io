<!DOCTYPE html>
<html lang="zh-CN">
    <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
    <meta charset="UTF-8" />

    <meta name="generator" content="Hugo 0.101.0" /><meta name="theme-color" content="#fff" />
    <meta name="color-scheme" content="light dark">

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
    <meta name="format-detection" content="telephone=no, date=no, address=no, email=no" />
    
    <meta http-equiv="Cache-Control" content="no-transform" />
    
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <title>机器学习-吴恩达 神经网络：表述（笔记） | Chloe&#39;s universe</title>

    <link rel="stylesheet" href="/css/meme.min.cb908ad1a8df1bd29011213e51b9bc319db3c34cb763b7026cbcdb94d4ad8710.css"/>

    
    
        <script src="/js/meme.min.99f22ee6fbbc7d4f7bcbca12b4a602587827428bc0ffd9b706e347fdcca8d0c1.js"></script>

    

    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />

        <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=EB&#43;Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto&#43;Serif&#43;SC:wght@400;500;700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" media="print" onload="this.media='all'" />
        <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=EB&#43;Garamond:ital,wght@0,400;0,500;0,700;1,400;1,700&amp;family=Noto&#43;Serif&#43;SC:wght@400;500;700&amp;family=Source&#43;Code&#43;Pro:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" /></noscript>

    <meta name="author" content="Chloe" /><meta name="description" content="@[toc] 神经元和大脑（Neurons and the brain） 在我们的大脑中有数个神经元： 这些神经元……" />

    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#2a6df4" />
    <link rel="apple-touch-icon" sizes="180x180" href="/icons/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-title" content="Chloe&#39;s universe" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="mobile-web-app-capable" content="yes" />
    <meta name="application-name" content="Chloe&#39;s universe" />
    <meta name="msapplication-starturl" content="../../" />
    <meta name="msapplication-TileColor" content="#fff" />
    <meta name="msapplication-TileImage" content="../../icons/mstile-150x150.png" />
    <link rel="manifest" href="/manifest.json" />

    
    

    
    <link rel="canonical" href="https://xiqi-zheng.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A1%A8%E8%BF%B0%E7%AC%94%E8%AE%B0/" />
    

<script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "datePublished": "2022-09-03T00:00:00+00:00",
        "dateModified": "2023-01-16T15:27:52+00:00",
        "url": "https://xiqi-zheng.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A1%A8%E8%BF%B0%E7%AC%94%E8%AE%B0/",
        "headline": "机器学习-吴恩达 神经网络：表述（笔记）",
        "description": "@[toc] 神经元和大脑（Neurons and the brain） 在我们的大脑中有数个神经元： 这些神经元……",
        "inLanguage" : "zh-CN",
        "articleSection": "posts",
        "wordCount":  1611 ,
        "image": ["https://img-blog.csdnimg.cn/706511de407d4ffa8914c9eab9556cdb.png","https://img-blog.csdnimg.cn/32e4ab5f869d4731b6ff64eacedeb6c7.png","https://img-blog.csdnimg.cn/517add91a9ff4fa593dadcfa966d2270.png","https://img-blog.csdnimg.cn/54655ac914974dcdba6bf676ae2e0bb4.png","https://img-blog.csdnimg.cn/dc91e5f8baeb401a95936680fb0efe87.png","https://img-blog.csdnimg.cn/15e35a70d43244099c11f93df4c11ab6.png","https://img-blog.csdnimg.cn/80ca65b6a99d4e34bf718a3a68bff2bf.png","https://img-blog.csdnimg.cn/ee8fdbb5c96f485c854adcef0aea1256.png","https://img-blog.csdnimg.cn/c983ced39a83407c9e9018d200366266.png","https://img-blog.csdnimg.cn/f5ab11798936495e868fc31b67b3ca4b.png","https://img-blog.csdnimg.cn/7460a2ae0351496683add53128b1d30b.png","https://img-blog.csdnimg.cn/a1e3c74b25824e598912528c2fbc3992.png","https://img-blog.csdnimg.cn/a67cf8fe4ed5400e8d9f4e3712d84459.png","https://img-blog.csdnimg.cn/d47835487fa44e6c876b6eb8d32f3a78.png","https://img-blog.csdnimg.cn/f5ed9017b3354627adf60ec6b74f4e8d.png","https://img-blog.csdnimg.cn/ee19cc2c9e2d4cfda6db0457505400fe.png"],
        "author": {
            "@type": "Person",
            "description": "Let there be light",
            "email": "1647656181@qq.com",
            "image": "https://xiqi-zheng.github.io/icons/apple-touch-icon.png",
            "url": "https://io-oi.me/",
            "name": "Chloe"
        },
        "license": "转载请保留本文作者以及本文链接",
        "publisher": {
            "@type": "Organization",
            "name": "Chloe's universe",
            "logo": {
                "@type": "ImageObject",
                "url": "https://xiqi-zheng.github.io/icons/apple-touch-icon.png"
            },
            "url": "https://xiqi-zheng.github.io/"
        },
        "mainEntityOfPage": {
            "@type": "WebSite",
            "@id": "https://xiqi-zheng.github.io/"
        }
    }
</script>

    

<meta name="twitter:card" content="summary_large_image" />



    



<meta property="og:title" content="机器学习-吴恩达 神经网络：表述（笔记）" />
<meta property="og:description" content="@[toc] 神经元和大脑（Neurons and the brain） 在我们的大脑中有数个神经元： 这些神经元……" />
<meta property="og:url" content="https://xiqi-zheng.github.io/posts/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E5%90%B4%E6%81%A9%E8%BE%BE-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%A1%A8%E8%BF%B0%E7%AC%94%E8%AE%B0/" />
<meta property="og:site_name" content="Chloe&#39;s universe" />
<meta property="og:locale" content="zh" /><meta property="og:image" content="https://img-blog.csdnimg.cn/706511de407d4ffa8914c9eab9556cdb.png" />
<meta property="og:type" content="article" />
    <meta property="article:published_time" content="2022-09-03T00:00:00&#43;00:00" />
    <meta property="article:modified_time" content="2023-01-16T15:27:52&#43;00:00" />
    
    <meta property="article:section" content="posts" />



    
    

    

<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@700&amp;text=reuixiy&amp;display=swap" media="print" onload="this.media='all'" />
<noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@700&amp;text=reuixiy&amp;display=swap" /></noscript>
</head>

    <body>
        <div class="container">
            
    <header class="header">
        
            <div class="header-wrapper">
                <div class="header-inner single">
                    
    <div class="site-brand">
        
            <a href="/" class="brand">Chloe&#39;s universe</a>
        
    </div>

                    <nav class="nav">
    <ul class="menu" id="menu">
        
            
        
        
        
        
            
                <li class="menu-item active"><a href="/posts/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon tech"><path d="M512 256c0 141.2-114.7 256-256 256C114.8 512 0 397.3 0 256S114.7 0 256 0s256 114.7 256 256zm-32 0c0-123.2-100.3-224-224-224C132.5 32 32 132.5 32 256s100.5 224 224 224 224-100.5 224-224zM160.9 124.6l86.9 37.1-37.1 86.9-86.9-37.1 37.1-86.9zm110 169.1l46.6 94h-14.6l-50-100-48.9 100h-14l51.1-106.9-22.3-9.4 6-14 68.6 29.1-6 14.3-16.5-7.1zm-11.8-116.3l68.6 29.4-29.4 68.3L230 246l29.1-68.6zm80.3 42.9l54.6 23.1-23.4 54.3-54.3-23.1 23.1-54.3z"/></svg><span class="menu-item-name">技术</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/random/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon random"><path d="M301.1 212c4.4 4.4 4.4 11.9 0 16.3l-9.7 9.7c-4.4 4.7-11.9 4.7-16.6 0l-10.5-10.5c-4.4-4.7-4.4-11.9 0-16.6l9.7-9.7c4.4-4.4 11.9-4.4 16.6 0l10.5 10.8zm-30.2-19.7c3-3 3-7.8 0-10.5-2.8-3-7.5-3-10.5 0-2.8 2.8-2.8 7.5 0 10.5 3.1 2.8 7.8 2.8 10.5 0zm-26 5.3c-3 2.8-3 7.5 0 10.2 2.8 3 7.5 3 10.5 0 2.8-2.8 2.8-7.5 0-10.2-3-3-7.7-3-10.5 0zm72.5-13.3c-19.9-14.4-33.8-43.2-11.9-68.1 21.6-24.9 40.7-17.2 59.8.8 11.9 11.3 29.3 24.9 17.2 48.2-12.5 23.5-45.1 33.2-65.1 19.1zm47.7-44.5c-8.9-10-23.3 6.9-15.5 16.1 7.4 9 32.1 2.4 15.5-16.1zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-66.2 42.6c2.5-16.1-20.2-16.6-25.2-25.7-13.6-24.1-27.7-36.8-54.5-30.4 11.6-8 23.5-6.1 23.5-6.1.3-6.4 0-13-9.4-24.9 3.9-12.5.3-22.4.3-22.4 15.5-8.6 26.8-24.4 29.1-43.2 3.6-31-18.8-59.2-49.8-62.8-22.1-2.5-43.7 7.7-54.3 25.7-23.2 40.1 1.4 70.9 22.4 81.4-14.4-1.4-34.3-11.9-40.1-34.3-6.6-25.7 2.8-49.8 8.9-61.4 0 0-4.4-5.8-8-8.9 0 0-13.8 0-24.6 5.3 11.9-15.2 25.2-14.4 25.2-14.4 0-6.4-.6-14.9-3.6-21.6-5.4-11-23.8-12.9-31.7 2.8.1-.2.3-.4.4-.5-5 11.9-1.1 55.9 16.9 87.2-2.5 1.4-9.1 6.1-13 10-21.6 9.7-56.2 60.3-56.2 60.3-28.2 10.8-77.2 50.9-70.6 79.7.3 3 1.4 5.5 3 7.5-2.8 2.2-5.5 5-8.3 8.3-11.9 13.8-5.3 35.2 17.7 24.4 15.8-7.2 29.6-20.2 36.3-30.4 0 0-5.5-5-16.3-4.4 27.7-6.6 34.3-9.4 46.2-9.1 8 3.9 8-34.3 8-34.3 0-14.7-2.2-31-11.1-41.5 12.5 12.2 29.1 32.7 28 60.6-.8 18.3-15.2 23-15.2 23-9.1 16.6-43.2 65.9-30.4 106 0 0-9.7-14.9-10.2-22.1-17.4 19.4-46.5 52.3-24.6 64.5 26.6 14.7 108.8-88.6 126.2-142.3 34.6-20.8 55.4-47.3 63.9-65 22 43.5 95.3 94.5 101.1 59z"/></svg><span class="menu-item-name">杂记</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href="/tags/"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512" class="icon tag"><path d="M497.941 225.941L286.059 14.059A48 48 0 0 0 252.118 0H48C21.49 0 0 21.49 0 48v204.118a48 48 0 0 0 14.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882 0l204.118-204.118c18.745-18.745 18.745-49.137 0-67.882zM112 160c-26.51 0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882 0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397 0h48.721a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882z"/></svg><span class="menu-item-name">标签</span></a>
                </li>
            
        
            
                <li class="menu-item"><a href=""><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" class="icon user-circle"><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 96c48.6 0 88 39.4 88 88s-39.4 88-88 88-88-39.4-88-88 39.4-88 88-88zm0 344c-58.7 0-111.3-26.6-146.5-68.2 18.8-35.4 55.6-59.8 98.5-59.8 2.4 0 4.8.4 7.1 1.1 13 4.2 26.6 6.9 40.9 6.9 14.3 0 28-2.7 40.9-6.9 2.3-.7 4.7-1.1 7.1-1.1 42.9 0 79.7 24.4 98.5 59.8C359.3 421.4 306.7 448 248 448z"/></svg><span class="menu-item-name">关于</span></a>
                </li>
            
        
            
                
                    
                    
                        <li class="menu-item">
                            <a id="theme-switcher" href="#"><span class="icon theme-icon-light">🌞</span><span class="icon theme-icon-dark">🌙</span></a>
                        </li>
                    
                
            
        
            
                
            
        
    </ul>
</nav>

                    
                </div>
            </div>
            

        
    </header>




            
            
    <main class="main single" id="main">
    <div class="main-inner">

        

        <article class="content post h-entry" data-align="justify" data-type="posts" data-toc-num="true">

            <h1 class="post-title p-name">机器学习-吴恩达 神经网络：表述（笔记）</h1>

            

            
                
            

            
                

<div class="post-meta">
    
    
    
    
    
    
    
    
</div>

            

            <nav class="contents">
  <h2 id="contents" class="contents-title">目录</h2><ol class="toc">
    <li><a id="contents:需求预测demand-prediction" href="#需求预测demand-prediction">需求预测（Demand Prediction）</a>
      <ol>
        <li><a id="contents:术语解释" href="#术语解释">术语解释</a></li>
        <li><a id="contents:多个hidden-layers" href="#多个hidden-layers">多个Hidden layers</a></li>
      </ol>
    </li>
  </ol>

  <ol>
    <li><a id="contents:线性逻辑-回归模型和神经网络" href="#线性逻辑-回归模型和神经网络">线性/逻辑 回归模型和神经网络</a></li>
  </ol>
</nav><div class="post-body e-content">
                <p>@[toc]</p>
<h1 id="神经元和大脑neurons-and-the-brain"><a href="#神经元和大脑neurons-and-the-brain" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:神经元和大脑neurons-and-the-brain" class="headings">神经元和大脑（Neurons and the brain）</a></h1>
<p>在我们的大脑中有数个神经元：</p>
<p><img src="https://img-blog.csdnimg.cn/706511de407d4ffa8914c9eab9556cdb.png" alt="在这里插入图片描述"></p>
<p>这些神经元接受着许许多多的信息，比如我们听到的声音和看到的图像，一个神经元接受到信息(input）后进行处理，然后把结果(output)传给下一个或多个神经元，这个结果（output）又变成了下一个或多个神经元的输入(input)，这就是它运作的基本原理。我们将这一个个的神经元叫做：<strong>激活单元（activation unit）</strong>。</p>
<p><img src="https://img-blog.csdnimg.cn/32e4ab5f869d4731b6ff64eacedeb6c7.png" alt="在这里插入图片描述"></p>
<p>是不是感觉这个过程似曾相识？对的！在前几章的线性回归和逻辑回归中，我们也是接受几个特征然后传入我们的模型最后输出答案。
但是呢，无论是线性回归还是逻辑回归都有一个致命缺点：<strong>当我们的特征数量非常庞大的时候，计算的负荷就会非常大。</strong>
比如我们如果想要训练一个模型来识别视觉对象（比如一张图片上的元素是人还是大猩猩），这个时候我们需要利用这些图片上的每个像素的值来作为特征。假设我们采用的是50*50像素的图片，并且我们将所有的像素视为特征，就会有2500个特征，如果我们进一步将两两特征组合成一个多项式模型，就会有接近3百万个特征。三百万个啊！兄弟们！作为普通的逻辑回归模型，是不可以有效地处理这么多特征的，那这个时候，我们就需要神经网络了！</p>
<h2 id="需求预测demand-prediction"><a href="#需求预测demand-prediction" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:需求预测demand-prediction" class="headings">需求预测（Demand Prediction）</a></h2>
<p>为了搞清楚神经网络是如何运作的，我们举个需求预测的例子。在这个例子中，我们尝试预测一个商品是否会成为销量第一。</p>
<p><img src="https://img-blog.csdnimg.cn/517add91a9ff4fa593dadcfa966d2270.png" alt="在这里插入图片描述"></p>
<p>上图中的a是activation也就是神经元（学习模型），上图的计算过程也就是一个只通过一个神经元来预测的模型。但其实现实生活中，不可能仅仅通过价格来判断一个商品是否会成为销量第一。
在现实生活中可能会有很多影响因素，比如：</p>
<p><img src="https://img-blog.csdnimg.cn/54655ac914974dcdba6bf676ae2e0bb4.png" alt="在这里插入图片描述"></p>
<p>假设上图的三个特征是我们觉得最能决定一件商品能否成为销量第一的元素。
但是呢我们现在手上掌握的数据只有：</p>
<p><img src="https://img-blog.csdnimg.cn/dc91e5f8baeb401a95936680fb0efe87.png" alt="在这里插入图片描述"></p>
<p>那怎么办呢？我们现在就需要对上图这四个特征进行组合来得到我们想要的三个特征：</p>
<p><img src="https://img-blog.csdnimg.cn/15e35a70d43244099c11f93df4c11ab6.png" alt="在这里插入图片描述"></p>
<p>这样呢，我们就得到了我们想要的三个特征，将这三个特征再放入下一层中进行计算，我们就能得到结果啦：</p>
<p><img src="https://img-blog.csdnimg.cn/80ca65b6a99d4e34bf718a3a68bff2bf.png" alt="在这里插入图片描述"></p>
<h3 id="术语解释"><a href="#术语解释" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:术语解释" class="headings">术语解释</a></h3>
<p><img src="https://img-blog.csdnimg.cn/ee8fdbb5c96f485c854adcef0aea1256.png" alt="在这里插入图片描述"></p>
<p>我们将四个我们能够直接得到的数据叫做input layer，中间的那一层我们叫做hidden layer，hidden layer中的元素我们叫做activations，最后一层我们叫做output layer。</p>
<h3 id="多个hidden-layers"><a href="#多个hidden-layers" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:多个hidden-layers" class="headings">多个Hidden layers</a></h3>
<p><img src="https://img-blog.csdnimg.cn/c983ced39a83407c9e9018d200366266.png" alt="在这里插入图片描述"></p>
<p>我们可以有多个hidden layer，我们可以进一步地对数据做更细致的处理。</p>
<h1 id="神经网络层"><a href="#神经网络层" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:神经网络层" class="headings">神经网络层</a></h1>
<p>其实呢，线性回归和逻辑回归就是只有一个神经元的神经网络：</p>
<p><img src="https://img-blog.csdnimg.cn/f5ab11798936495e868fc31b67b3ca4b.png" alt="在这里插入图片描述"></p>
<p>让我们观察上面一张图，其中的x就是一组特征值。把第二层展开我们会发现里面有三个神经元，那么<strong>每个神经元都是一个逻辑回归模型</strong>，在经过这三个神经元也就是三个回归模型的处理后就得到的a，也就是output。</p>
<p><img src="https://img-blog.csdnimg.cn/7460a2ae0351496683add53128b1d30b.png" alt="在这里插入图片描述"></p>
<p>我们把每一组的神经元叫做<strong>layer</strong>，根据传统写法，我们将原始的特征数据<strong>x称为layer0</strong>。</p>
<p><img src="https://img-blog.csdnimg.cn/a1e3c74b25824e598912528c2fbc3992.png" alt="在这里插入图片描述"></p>
<p>我们会在表达数据的时候加上右上角标来表示它是在哪一层中。</p>
<p><img src="https://img-blog.csdnimg.cn/a67cf8fe4ed5400e8d9f4e3712d84459.png" alt="在这里插入图片描述"></p>
<p>现在我们将layer2展开，我们会发现里面只有一个神经元并且是一个逻辑回归模型，它输出的是一个标量。单独取出这个layer2我们会发现，这其实就是我们之前学的逻辑回归模型。</p>
<p><img src="https://img-blog.csdnimg.cn/d47835487fa44e6c876b6eb8d32f3a78.png" alt="在这里插入图片描述"></p>
<p>最后呢，我们只需要对最后的输出结果做一个判断，就完成了。</p>
<h2 id="线性逻辑-回归模型和神经网络"><a href="#线性逻辑-回归模型和神经网络" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:线性逻辑-回归模型和神经网络" class="headings">线性/逻辑 回归模型和神经网络</a></h2>
<p>线性/逻辑 回归模型其实就是只含有一个神经元的单层的神经网络。
在处理复杂的数据时，神经网络能够更好地进行预测，比如在处理图像时。其实在数据量非常大的现代社会，大部分的数据都是复杂的，这也是为什么神经网络在今天这么火的原因。</p>
<h1 id="更加复杂的神经网络"><a href="#更加复杂的神经网络" class="anchor-link"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon anchor-icon"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"/></svg></a><a href="#contents:更加复杂的神经网络" class="headings">更加复杂的神经网络</a></h1>
<p>现在让我们来看看多层的神经网络：</p>
<p><img src="https://img-blog.csdnimg.cn/f5ed9017b3354627adf60ec6b74f4e8d.png" alt="在这里插入图片描述"></p>
<p>我们展开layer3，会发现layer3的用到了layer2的output作为它的input，那么现在来做个小小测试，往圈起来的地方的右上角标填入数字。
.
.
.</p>
<p>正确答案是：3，3，2，3 ；你们填对了吗？
layer2中的w和b都是使用了自己的学习模型中的参数，但是a使用的是layer2的output。</p>
<p><img src="https://img-blog.csdnimg.cn/ee19cc2c9e2d4cfda6db0457505400fe.png" alt="在这里插入图片描述"></p>

            </div>

            


        </article>

        

        


        


        


        


        


        
    <footer class="minimal-footer">
        
            <div class="post-tag"><a href="/tags/machine-learning/" rel="tag" class="post-tag-link">#machine-learning</a></div>
        
        
        
            
        
    </footer>



        


        


        


    </div>
</main>


            
    <div id="back-to-top" class="back-to-top">
        <a href="#"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon arrow-up"><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg></a>
    </div>


            

        </div>
        <script>
        if ('serviceWorker' in navigator) {
            window.addEventListener('load', function() {
                navigator.serviceWorker.register('\/sw.js');
            });
        }
    </script>


        








    <script src="https://cdn.jsdelivr.net/npm/medium-zoom@latest/dist/medium-zoom.min.js"></script>

<script>
    let imgNodes = document.querySelectorAll('div.post-body img');
    imgNodes = Array.from(imgNodes).filter(node => node.parentNode.tagName !== "A");

    mediumZoom(imgNodes, {
        background: 'hsla(var(--color-bg-h), var(--color-bg-s), var(--color-bg-l), 0.95)'
    })
</script>




    <script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js" type="module" defer></script>






    </body>
</html>
